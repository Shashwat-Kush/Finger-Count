{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU10HXKVWj6U"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.metrics import pairwise\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Initialising global variable \n",
        "background =None\n",
        "accumulated_weight = 0.5\n",
        "#Selecting the Region of interest initially\n",
        "roi_top = 50\n",
        "roi_bottom = 500\n",
        "roi_right = 500\n",
        "roi_left = 800\n"
      ],
      "metadata": {
        "id": "xNVQl8NmWlxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For a stable background or to distinguish between background and foreground, we try to take the average of frames. \n",
        "\n",
        "def accu_avg(frame, accumulated_weight):\n",
        "  global background\n",
        "\n",
        "  #Checking just in case the background is not assigned yet.\n",
        "  if background is None:\n",
        "    background = frame.copy().astype(\"float\")\n",
        "    return None\n",
        "  \n",
        "  cv2.accumulateWeighted(frame, background, accumulated_weight)"
      ],
      "metadata": {
        "id": "MZ76qE4VdQIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This function is used to detect the hand contour from the frame or image provided.\n",
        "\n",
        "def segment(frame,threshold=25):\n",
        "  global background\n",
        "\n",
        "  #Absolute difference is helpful inremoving the stationary background in the frame so that thresholding can give us a better look at the region of interest.\n",
        "  diff = cv2.absdiff(background.astype(\"uint8\"), frame)\n",
        "\n",
        "  _ , thresh = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)\n",
        "  from google.colab.patches import cv2_imshow\n",
        "  #We look for contours in the thresholded frame.\n",
        "  image, contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  \n",
        "  if len(contours) == None:\n",
        "    return None  #If there are no contours, then we exit the function with no fingers to count\n",
        "  else:\n",
        "    # If we detect the contours, then we would be looking for the biggeest one that will be signifying the hand\n",
        "    hand_segment = max(contours,key = cv2.contourArea)\n",
        "\n",
        "  return thresh , hand_segment\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bk00qgQNfg3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to count the fingers\n",
        "\n",
        "def finger_count(thresh,hand_segment):\n",
        "\n",
        "  # Draw the convex hull to detect the extreme points of the hand segment.\n",
        "  hull = cv2.convexHull(hand_segment)\n",
        "\n",
        "  # Extracting the extreme points of convex hull\n",
        "  top    = tuple(hull[hull[:, :, 1].argmin()][0])\n",
        "  bottom = tuple(hull[hull[:, :, 1].argmax()][0])\n",
        "  left   = tuple(hull[hull[:, :, 0].argmin()][0])\n",
        "  right  = tuple(hull[hull[:, :, 0].argmax()][0])\n",
        "\n",
        "  # Approximating the co-orsdinates of the center of hand segment\n",
        "  cX = (left[0] + right[0]) // 2\n",
        "  cY = (top[1] + bottom[1]) // 2\n",
        "\n",
        "  # Calculates the distance between center and extreme points of the hull.\n",
        "  distance = pairwise.euclidean_distances([(cX, cY)], Y=[left, right, top, bottom])[0]\n",
        "\n",
        "  # To further refine the region of interest, we take the max distance from the centre as the radius and make a circle of that around the center.\n",
        "  max_distance = distance.max()\n",
        "  radius = int(0.8 * max_distance)\n",
        "  circumference = (2 * np.pi * radius)\n",
        "  circular_roi = np.zeros(thresholded.shape[:2], dtype=\"uint8\")\n",
        "  cv2.circle(circular_roi, (cX, cY), radius, 255, 10)\n",
        "  \n",
        "  # The function then applies a bitwise AND operation to obtain only the pixels of the thresholded image that are inside the circular ROI.\n",
        "  circular_roi = cv2.bitwise_and(thresholded, thresholded, mask=circular_roi)\n",
        "\n",
        "  # It finds the countours in this ROI. \n",
        "  image, contours, hierarchy = cv2.findContours(circular_roi.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "  count = 0\n",
        "\n",
        "  # This loop checks if contours are not in the wrist region or not, by defining the region of wrist and checking if the countour lies in the region.\n",
        "  for cnt in contours:\n",
        "    (x, y, w, h) = cv2.boundingRect(cnt)\n",
        "    out_of_wrist = ((cY + (cY * 0.25)) > (y + h))\n",
        "   \n",
        "    #limit_points = ((circumference * 0.25) > cnt.shape[0])\n",
        "\n",
        "    if  out_of_wrist :\n",
        "       count += 1  # Finally if it is not in the wrist region, then it is a finger.\n",
        "\n",
        "  return count\n",
        "\n"
      ],
      "metadata": {
        "id": "VzaxPbK9n_Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize camera object\n",
        "cam = cv2.VideoCapture(\"/VID_20230504_190552.mp4\")\n",
        "\n",
        "# Counter variable for number of frames processed\n",
        "num_frames = 0\n",
        "\n",
        "# Loop infinitely\n",
        "while True:\n",
        "\n",
        "    # Capture frame from camera\n",
        "    ret, frame = cam.read()\n",
        "    print(\"hello\")\n",
        "    # Flip the frame horizontally\n",
        "    frame = cv2.flip(frame, 1)\n",
        "\n",
        "    # Create a copy of the frame for drawing purposes\n",
        "    frame_copy = frame.copy()\n",
        "\n",
        "    # Set region of interest (ROI) for detecting hand\n",
        "    roi = frame[roi_top:roi_bottom, roi_right:roi_left]\n",
        "\n",
        "    # Convert ROI to grayscale and apply Gaussian blur to reduce noise\n",
        "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
        "\n",
        "    # If the number of frames processed is less than 60, calculate the accumulated weighted average for background removal\n",
        "    if num_frames < 60:\n",
        "        accu_avg(gray, accumulated_weight)\n",
        "        # Display \"WAIT! GETTING BACKGROUND AVG.\" message during this time\n",
        "        if num_frames <= 59:\n",
        "            cv2.putText(frame_copy, \"WAIT! GETTING BACKGROUND AVG.\", (200, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "            cv2_imshow(frame_copy)\n",
        "            \n",
        "    # If the number of frames processed is greater than or equal to 60, segment the hand and count the fingers\n",
        "    else:\n",
        "        # Segment the hand from the background\n",
        "        hand = segment(gray)\n",
        "\n",
        "        # If the hand is detected in the ROI, draw a contour around it and count the fingers\n",
        "        if hand is not None:\n",
        "            thresholded, hand_segment = hand\n",
        "            cv2.drawContours(frame_copy, [hand_segment + (roi_right, roi_top)], -1, (255, 0, 0),1)\n",
        "            fingers = finger_count(thresholded, hand_segment)\n",
        "            cv2.putText(frame_copy, str(fingers), (70, 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
        "            cv2_imshow(thresholded)\n",
        "\n",
        "    # Draw the ROI on the frame\n",
        "    cv2.rectangle(frame_copy, (roi_left, roi_top), (roi_right, roi_bottom), (0,0,255), 5)\n",
        "\n",
        "    # Increment the number of frames processed\n",
        "    num_frames += 1\n",
        "\n",
        "    # Display the resulting frame\n",
        "    cv2_imshow(frame_copy)\n",
        "\n",
        "    # Wait for a keypress, and check if the Esc key was pressed to break the loop\n",
        "    k = cv2.waitKey(1) & 0xFF\n",
        "    if k == 27:\n",
        "        break\n",
        "\n",
        "# Release the camera object and destroy all windows\n",
        "cam.release()\n",
        "cv2.destroyAllWindows() \n"
      ],
      "metadata": {
        "id": "DxPuaevvzAdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IlboBjReDjAc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}